{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 2))`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 2))`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 2))`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 1))`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8036, 160, 320, 3)\n",
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/3\n",
      "6428/6428 [==============================] - ETA: 20224s - loss: 0.007 - ETA: 12838s - loss: 7579.15 - ETA: 9122s - loss: 5196.8177 - ETA: 7256s - loss: 3934.426 - ETA: 6125s - loss: 3197.163 - ETA: 5376s - loss: 2683.604 - ETA: 4834s - loss: 2301.925 - ETA: 4431s - loss: 2016.359 - ETA: 4115s - loss: 1796.793 - ETA: 3866s - loss: 1618.663 - ETA: 3657s - loss: 1471.577 - ETA: 3482s - loss: 1349.614 - ETA: 3328s - loss: 1247.332 - ETA: 3199s - loss: 1159.225 - ETA: 3083s - loss: 1082.241 - ETA: 2983s - loss: 1014.613 - ETA: 2891s - loss: 955.072 - ETA: 2806s - loss: 902.31 - ETA: 2730s - loss: 855.17 - ETA: 2661s - loss: 812.67 - ETA: 2598s - loss: 774.09 - ETA: 2539s - loss: 738.94 - ETA: 2485s - loss: 706.82 - ETA: 2435s - loss: 677.39 - ETA: 2388s - loss: 650.35 - ETA: 2345s - loss: 625.42 - ETA: 2304s - loss: 602.34 - ETA: 2264s - loss: 580.90 - ETA: 2227s - loss: 560.91 - ETA: 2192s - loss: 542.23 - ETA: 2158s - loss: 524.76 - ETA: 2126s - loss: 508.37 - ETA: 2095s - loss: 492.96 - ETA: 2067s - loss: 478.47 - ETA: 2039s - loss: 464.80 - ETA: 2012s - loss: 451.89 - ETA: 1985s - loss: 439.68 - ETA: 1960s - loss: 428.12 - ETA: 1936s - loss: 417.15 - ETA: 1913s - loss: 406.72 - ETA: 1891s - loss: 396.81 - ETA: 1869s - loss: 387.36 - ETA: 1847s - loss: 378.36 - ETA: 1826s - loss: 369.76 - ETA: 1806s - loss: 361.55 - ETA: 1787s - loss: 353.69 - ETA: 1767s - loss: 346.17 - ETA: 1748s - loss: 338.96 - ETA: 1728s - loss: 332.04 - ETA: 1710s - loss: 325.40 - ETA: 1692s - loss: 319.02 - ETA: 1674s - loss: 312.89 - ETA: 1657s - loss: 306.98 - ETA: 1639s - loss: 301.30 - ETA: 1622s - loss: 295.82 - ETA: 1606s - loss: 290.54 - ETA: 1590s - loss: 285.44 - ETA: 1574s - loss: 280.52 - ETA: 1560s - loss: 275.77 - ETA: 1545s - loss: 271.17 - ETA: 1530s - loss: 266.73 - ETA: 1515s - loss: 262.43 - ETA: 1501s - loss: 258.26 - ETA: 1486s - loss: 254.23 - ETA: 1472s - loss: 250.32 - ETA: 1457s - loss: 246.52 - ETA: 1443s - loss: 242.84 - ETA: 1429s - loss: 239.27 - ETA: 1416s - loss: 235.81 - ETA: 1403s - loss: 232.44 - ETA: 1389s - loss: 229.16 - ETA: 1376s - loss: 225.98 - ETA: 1363s - loss: 222.89 - ETA: 1350s - loss: 219.87 - ETA: 1337s - loss: 216.94 - ETA: 1324s - loss: 214.09 - ETA: 1311s - loss: 211.31 - ETA: 1298s - loss: 208.60 - ETA: 1286s - loss: 205.96 - ETA: 1273s - loss: 203.39 - ETA: 1260s - loss: 200.87 - ETA: 1248s - loss: 198.43 - ETA: 1235s - loss: 196.03 - ETA: 1223s - loss: 193.70 - ETA: 1210s - loss: 191.42 - ETA: 1198s - loss: 189.20 - ETA: 1186s - loss: 187.02 - ETA: 1174s - loss: 184.90 - ETA: 1162s - loss: 182.82 - ETA: 1151s - loss: 180.79 - ETA: 1139s - loss: 178.80 - ETA: 1128s - loss: 176.86 - ETA: 1116s - loss: 174.96 - ETA: 1104s - loss: 173.10 - ETA: 1092s - loss: 171.27 - ETA: 1081s - loss: 169.49 - ETA: 1069s - loss: 167.74 - ETA: 1058s - loss: 166.03 - ETA: 1046s - loss: 164.36 - ETA: 1035s - loss: 162.71 - ETA: 1023s - loss: 161.10 - ETA: 1012s - loss: 159.52 - ETA: 1001s - loss: 157.97 - ETA: 989s - loss: 156.4603 - ETA: 978s - loss: 154.970 - ETA: 967s - loss: 153.508 - ETA: 956s - loss: 152.074 - ETA: 947s - loss: 150.666 - ETA: 936s - loss: 149.284 - ETA: 925s - loss: 147.927 - ETA: 914s - loss: 146.594 - ETA: 903s - loss: 145.286 - ETA: 893s - loss: 144.000 - ETA: 882s - loss: 142.737 - ETA: 871s - loss: 141.496 - ETA: 861s - loss: 140.277 - ETA: 850s - loss: 139.078 - ETA: 840s - loss: 137.899 - ETA: 829s - loss: 136.741 - ETA: 818s - loss: 135.601 - ETA: 808s - loss: 134.481 - ETA: 799s - loss: 133.379 - ETA: 788s - loss: 132.294 - ETA: 778s - loss: 131.228 - ETA: 767s - loss: 130.178 - ETA: 757s - loss: 129.145 - ETA: 746s - loss: 128.128 - ETA: 736s - loss: 127.127 - ETA: 726s - loss: 126.142 - ETA: 716s - loss: 125.172 - ETA: 705s - loss: 124.216 - ETA: 695s - loss: 123.275 - ETA: 685s - loss: 122.349 - ETA: 674s - loss: 121.436 - ETA: 664s - loss: 120.536 - ETA: 654s - loss: 119.650 - ETA: 644s - loss: 118.777 - ETA: 633s - loss: 117.916 - ETA: 624s - loss: 117.068 - ETA: 614s - loss: 116.232 - ETA: 604s - loss: 115.408 - ETA: 593s - loss: 114.595 - ETA: 583s - loss: 113.794 - ETA: 573s - loss: 113.004 - ETA: 562s - loss: 112.224 - ETA: 552s - loss: 111.456 - ETA: 542s - loss: 110.698 - ETA: 532s - loss: 109.950 - ETA: 521s - loss: 109.212 - ETA: 511s - loss: 108.484 - ETA: 501s - loss: 107.766 - ETA: 491s - loss: 107.057 - ETA: 481s - loss: 106.358 - ETA: 472s - loss: 105.667 - ETA: 462s - loss: 104.986 - ETA: 452s - loss: 104.313 - ETA: 442s - loss: 103.648 - ETA: 432s - loss: 102.992 - ETA: 421s - loss: 102.345 - ETA: 411s - loss: 101.705 - ETA: 401s - loss: 101.074 - ETA: 391s - loss: 100.450 - ETA: 381s - loss: 99.834 - ETA: 370s - loss: 99.22 - ETA: 360s - loss: 98.62 - ETA: 350s - loss: 98.03 - ETA: 340s - loss: 97.44 - ETA: 330s - loss: 96.86 - ETA: 320s - loss: 96.29 - ETA: 310s - loss: 95.72 - ETA: 300s - loss: 95.16 - ETA: 290s - loss: 94.61 - ETA: 280s - loss: 94.06 - ETA: 270s - loss: 93.52 - ETA: 260s - loss: 92.98 - ETA: 250s - loss: 92.46 - ETA: 240s - loss: 91.93 - ETA: 229s - loss: 91.42 - ETA: 219s - loss: 90.91 - ETA: 209s - loss: 90.40 - ETA: 199s - loss: 89.90 - ETA: 189s - loss: 89.41 - ETA: 179s - loss: 88.92 - ETA: 169s - loss: 88.44 - ETA: 159s - loss: 87.96 - ETA: 149s - loss: 87.49 - ETA: 139s - loss: 87.02 - ETA: 129s - loss: 86.56 - ETA: 119s - loss: 86.10 - ETA: 109s - loss: 85.64 - ETA: 99s - loss: 85.2008 - ETA: 88s - loss: 84.757 - ETA: 78s - loss: 84.318 - ETA: 68s - loss: 83.883 - ETA: 58s - loss: 83.453 - ETA: 48s - loss: 83.027 - ETA: 38s - loss: 82.606 - ETA: 28s - loss: 82.189 - ETA: 18s - loss: 81.776 - ETA: 8s - loss: 81.367 - 2162s - loss: 81.0132 - val_loss: 0.0162\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6428/6428 [==============================] - ETA: 1876s - loss: 0.01 - ETA: 5622s - loss: 0.01 - ETA: 4340s - loss: 0.01 - ETA: 3694s - loss: 0.01 - ETA: 3303s - loss: 0.01 - ETA: 3043s - loss: 0.01 - ETA: 2851s - loss: 0.01 - ETA: 2697s - loss: 0.01 - ETA: 2579s - loss: 0.01 - ETA: 2484s - loss: 0.01 - ETA: 2401s - loss: 0.01 - ETA: 2331s - loss: 0.01 - ETA: 2270s - loss: 0.01 - ETA: 2218s - loss: 0.01 - ETA: 2169s - loss: 0.01 - ETA: 2126s - loss: 0.01 - ETA: 2089s - loss: 0.01 - ETA: 2057s - loss: 0.01 - ETA: 2026s - loss: 0.01 - ETA: 1999s - loss: 0.01 - ETA: 1972s - loss: 0.01 - ETA: 1944s - loss: 0.01 - ETA: 1920s - loss: 0.01 - ETA: 1896s - loss: 0.01 - ETA: 1876s - loss: 0.01 - ETA: 1856s - loss: 0.01 - ETA: 1835s - loss: 0.01 - ETA: 1815s - loss: 0.01 - ETA: 1796s - loss: 0.01 - ETA: 1777s - loss: 0.01 - ETA: 1759s - loss: 0.01 - ETA: 1742s - loss: 0.01 - ETA: 1726s - loss: 0.01 - ETA: 1711s - loss: 0.01 - ETA: 1695s - loss: 0.01 - ETA: 1680s - loss: 0.01 - ETA: 1664s - loss: 0.01 - ETA: 1651s - loss: 0.01 - ETA: 1637s - loss: 0.01 - ETA: 1622s - loss: 0.01 - ETA: 1608s - loss: 0.01 - ETA: 1596s - loss: 0.01 - ETA: 1583s - loss: 0.01 - ETA: 1570s - loss: 0.01 - ETA: 1558s - loss: 0.01 - ETA: 1546s - loss: 0.01 - ETA: 1532s - loss: 0.01 - ETA: 1520s - loss: 0.01 - ETA: 1508s - loss: 0.01 - ETA: 1497s - loss: 0.01 - ETA: 1486s - loss: 0.01 - ETA: 1474s - loss: 0.01 - ETA: 1462s - loss: 0.01 - ETA: 1450s - loss: 0.01 - ETA: 1438s - loss: 0.01 - ETA: 1425s - loss: 0.01 - ETA: 1413s - loss: 0.01 - ETA: 1402s - loss: 0.01 - ETA: 1390s - loss: 0.01 - ETA: 1379s - loss: 0.01 - ETA: 1368s - loss: 0.01 - ETA: 1357s - loss: 0.01 - ETA: 1346s - loss: 0.01 - ETA: 1335s - loss: 0.01 - ETA: 1324s - loss: 0.01 - ETA: 1313s - loss: 0.01 - ETA: 1302s - loss: 0.01 - ETA: 1291s - loss: 0.01 - ETA: 1281s - loss: 0.01 - ETA: 1270s - loss: 0.01 - ETA: 1260s - loss: 0.01 - ETA: 1249s - loss: 0.01 - ETA: 1238s - loss: 0.01 - ETA: 1227s - loss: 0.01 - ETA: 1217s - loss: 0.01 - ETA: 1206s - loss: 0.01 - ETA: 1196s - loss: 0.01 - ETA: 1186s - loss: 0.01 - ETA: 1175s - loss: 0.01 - ETA: 1164s - loss: 0.01 - ETA: 1154s - loss: 0.01 - ETA: 1144s - loss: 0.01 - ETA: 1134s - loss: 0.01 - ETA: 1123s - loss: 0.01 - ETA: 1113s - loss: 0.01 - ETA: 1103s - loss: 0.01 - ETA: 1092s - loss: 0.01 - ETA: 1082s - loss: 0.01 - ETA: 1072s - loss: 0.01 - ETA: 1062s - loss: 0.01 - ETA: 1052s - loss: 0.01 - ETA: 1042s - loss: 0.01 - ETA: 1032s - loss: 0.01 - ETA: 1022s - loss: 0.01 - ETA: 1012s - loss: 0.01 - ETA: 1001s - loss: 0.01 - ETA: 991s - loss: 0.0144 - ETA: 982s - loss: 0.014 - ETA: 972s - loss: 0.014 - ETA: 962s - loss: 0.014 - ETA: 952s - loss: 0.014 - ETA: 942s - loss: 0.014 - ETA: 932s - loss: 0.014 - ETA: 922s - loss: 0.014 - ETA: 913s - loss: 0.014 - ETA: 903s - loss: 0.014 - ETA: 894s - loss: 0.014 - ETA: 884s - loss: 0.014 - ETA: 874s - loss: 0.014 - ETA: 865s - loss: 0.014 - ETA: 855s - loss: 0.014 - ETA: 846s - loss: 0.014 - ETA: 836s - loss: 0.014 - ETA: 826s - loss: 0.014 - ETA: 816s - loss: 0.014 - ETA: 806s - loss: 0.014 - ETA: 797s - loss: 0.014 - ETA: 787s - loss: 0.014 - ETA: 777s - loss: 0.014 - ETA: 768s - loss: 0.014 - ETA: 758s - loss: 0.014 - ETA: 748s - loss: 0.014 - ETA: 739s - loss: 0.013 - ETA: 729s - loss: 0.014 - ETA: 719s - loss: 0.014 - ETA: 710s - loss: 0.014 - ETA: 700s - loss: 0.014 - ETA: 690s - loss: 0.014 - ETA: 681s - loss: 0.014 - ETA: 671s - loss: 0.014 - ETA: 661s - loss: 0.014 - ETA: 652s - loss: 0.014 - ETA: 642s - loss: 0.014 - ETA: 632s - loss: 0.014 - ETA: 623s - loss: 0.014 - ETA: 613s - loss: 0.014 - ETA: 604s - loss: 0.014 - ETA: 594s - loss: 0.014 - ETA: 584s - loss: 0.014 - ETA: 575s - loss: 0.014 - ETA: 565s - loss: 0.014 - ETA: 556s - loss: 0.014 - ETA: 546s - loss: 0.014 - ETA: 536s - loss: 0.014 - ETA: 527s - loss: 0.014 - ETA: 517s - loss: 0.014 - ETA: 508s - loss: 0.014 - ETA: 498s - loss: 0.014 - ETA: 489s - loss: 0.014 - ETA: 479s - loss: 0.014 - ETA: 470s - loss: 0.014 - ETA: 460s - loss: 0.014 - ETA: 450s - loss: 0.014 - ETA: 441s - loss: 0.014 - ETA: 431s - loss: 0.014 - ETA: 422s - loss: 0.014 - ETA: 412s - loss: 0.014 - ETA: 403s - loss: 0.014 - ETA: 393s - loss: 0.014 - ETA: 384s - loss: 0.014 - ETA: 375s - loss: 0.014 - ETA: 365s - loss: 0.014 - ETA: 356s - loss: 0.014 - ETA: 346s - loss: 0.014 - ETA: 337s - loss: 0.014 - ETA: 327s - loss: 0.014 - ETA: 318s - loss: 0.014 - ETA: 309s - loss: 0.014 - ETA: 299s - loss: 0.014 - ETA: 290s - loss: 0.014 - ETA: 280s - loss: 0.014 - ETA: 271s - loss: 0.014 - ETA: 261s - loss: 0.014 - ETA: 252s - loss: 0.014 - ETA: 242s - loss: 0.014 - ETA: 233s - loss: 0.014 - ETA: 224s - loss: 0.013 - ETA: 214s - loss: 0.013 - ETA: 205s - loss: 0.013 - ETA: 195s - loss: 0.013 - ETA: 186s - loss: 0.013 - ETA: 177s - loss: 0.013 - ETA: 167s - loss: 0.013 - ETA: 158s - loss: 0.013 - ETA: 148s - loss: 0.013 - ETA: 139s - loss: 0.013 - ETA: 130s - loss: 0.013 - ETA: 120s - loss: 0.013 - ETA: 111s - loss: 0.013 - ETA: 101s - loss: 0.013 - ETA: 92s - loss: 0.013 - ETA: 83s - loss: 0.01 - ETA: 73s - loss: 0.01 - ETA: 64s - loss: 0.01 - ETA: 55s - loss: 0.01 - ETA: 45s - loss: 0.01 - ETA: 36s - loss: 0.01 - ETA: 26s - loss: 0.01 - ETA: 17s - loss: 0.01 - ETA: 8s - loss: 0.0141 - 1998s - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6428/6428 [==============================] - ETA: 1861s - loss: 0.07 - ETA: 1831s - loss: 0.03 - ETA: 1834s - loss: 0.02 - ETA: 1846s - loss: 0.02 - ETA: 1832s - loss: 0.02 - ETA: 1814s - loss: 0.01 - ETA: 1798s - loss: 0.01 - ETA: 1785s - loss: 0.01 - ETA: 1773s - loss: 0.01 - ETA: 1765s - loss: 0.01 - ETA: 1752s - loss: 0.01 - ETA: 1742s - loss: 0.01 - ETA: 1730s - loss: 0.01 - ETA: 1723s - loss: 0.01 - ETA: 1713s - loss: 0.01 - ETA: 1702s - loss: 0.01 - ETA: 1694s - loss: 0.01 - ETA: 1687s - loss: 0.01 - ETA: 1677s - loss: 0.01 - ETA: 1667s - loss: 0.01 - ETA: 1658s - loss: 0.01 - ETA: 1650s - loss: 0.01 - ETA: 1640s - loss: 0.01 - ETA: 1631s - loss: 0.01 - ETA: 1620s - loss: 0.01 - ETA: 1610s - loss: 0.01 - ETA: 1600s - loss: 0.01 - ETA: 1591s - loss: 0.01 - ETA: 1581s - loss: 0.01 - ETA: 1574s - loss: 0.01 - ETA: 1566s - loss: 0.01 - ETA: 1556s - loss: 0.01 - ETA: 1546s - loss: 0.01 - ETA: 1536s - loss: 0.01 - ETA: 1527s - loss: 0.01 - ETA: 1520s - loss: 0.01 - ETA: 1510s - loss: 0.01 - ETA: 1502s - loss: 0.01 - ETA: 1492s - loss: 0.01 - ETA: 1483s - loss: 0.01 - ETA: 1474s - loss: 0.01 - ETA: 1465s - loss: 0.01 - ETA: 1455s - loss: 0.01 - ETA: 1446s - loss: 0.01 - ETA: 1438s - loss: 0.01 - ETA: 1428s - loss: 0.01 - ETA: 1418s - loss: 0.01 - ETA: 1409s - loss: 0.01 - ETA: 1400s - loss: 0.01 - ETA: 1390s - loss: 0.01 - ETA: 1381s - loss: 0.01 - ETA: 1371s - loss: 0.01 - ETA: 1361s - loss: 0.01 - ETA: 1352s - loss: 0.01 - ETA: 1344s - loss: 0.01 - ETA: 1335s - loss: 0.01 - ETA: 1325s - loss: 0.01 - ETA: 1315s - loss: 0.01 - ETA: 1306s - loss: 0.01 - ETA: 1296s - loss: 0.01 - ETA: 1286s - loss: 0.01 - ETA: 1277s - loss: 0.01 - ETA: 1268s - loss: 0.01 - ETA: 1259s - loss: 0.01 - ETA: 1250s - loss: 0.01 - ETA: 1241s - loss: 0.01 - ETA: 1233s - loss: 0.01 - ETA: 1223s - loss: 0.01 - ETA: 1214s - loss: 0.01 - ETA: 1206s - loss: 0.01 - ETA: 1197s - loss: 0.01 - ETA: 1188s - loss: 0.01 - ETA: 1179s - loss: 0.01 - ETA: 1170s - loss: 0.01 - ETA: 1160s - loss: 0.01 - ETA: 1151s - loss: 0.01 - ETA: 1142s - loss: 0.01 - ETA: 1133s - loss: 0.01 - ETA: 1123s - loss: 0.01 - ETA: 1114s - loss: 0.01 - ETA: 1105s - loss: 0.01 - ETA: 1095s - loss: 0.01 - ETA: 1086s - loss: 0.01 - ETA: 1076s - loss: 0.01 - ETA: 1067s - loss: 0.01 - ETA: 1057s - loss: 0.01 - ETA: 1048s - loss: 0.01 - ETA: 1039s - loss: 0.01 - ETA: 1030s - loss: 0.01 - ETA: 1021s - loss: 0.01 - ETA: 1012s - loss: 0.01 - ETA: 1003s - loss: 0.01 - ETA: 993s - loss: 0.0120 - ETA: 984s - loss: 0.012 - ETA: 975s - loss: 0.012 - ETA: 965s - loss: 0.012 - ETA: 956s - loss: 0.012 - ETA: 946s - loss: 0.012 - ETA: 937s - loss: 0.012 - ETA: 928s - loss: 0.012 - ETA: 918s - loss: 0.012 - ETA: 909s - loss: 0.012 - ETA: 900s - loss: 0.012 - ETA: 891s - loss: 0.012 - ETA: 881s - loss: 0.012 - ETA: 872s - loss: 0.012 - ETA: 863s - loss: 0.012 - ETA: 853s - loss: 0.012 - ETA: 844s - loss: 0.012 - ETA: 835s - loss: 0.012 - ETA: 826s - loss: 0.012 - ETA: 817s - loss: 0.012 - ETA: 807s - loss: 0.012 - ETA: 798s - loss: 0.012 - ETA: 789s - loss: 0.012 - ETA: 779s - loss: 0.012 - ETA: 770s - loss: 0.012 - ETA: 761s - loss: 0.012 - ETA: 752s - loss: 0.012 - ETA: 742s - loss: 0.012 - ETA: 733s - loss: 0.012 - ETA: 724s - loss: 0.012 - ETA: 715s - loss: 0.012 - ETA: 706s - loss: 0.012 - ETA: 697s - loss: 0.012 - ETA: 687s - loss: 0.012 - ETA: 678s - loss: 0.012 - ETA: 669s - loss: 0.012 - ETA: 660s - loss: 0.012 - ETA: 650s - loss: 0.012 - ETA: 641s - loss: 0.012 - ETA: 632s - loss: 0.012 - ETA: 623s - loss: 0.012 - ETA: 614s - loss: 0.012 - ETA: 604s - loss: 0.012 - ETA: 595s - loss: 0.012 - ETA: 586s - loss: 0.012 - ETA: 577s - loss: 0.012 - ETA: 568s - loss: 0.012 - ETA: 559s - loss: 0.012 - ETA: 549s - loss: 0.012 - ETA: 540s - loss: 0.012 - ETA: 531s - loss: 0.012 - ETA: 522s - loss: 0.012 - ETA: 513s - loss: 0.012 - ETA: 503s - loss: 0.012 - ETA: 494s - loss: 0.012 - ETA: 485s - loss: 0.012 - ETA: 476s - loss: 0.012 - ETA: 467s - loss: 0.012 - ETA: 458s - loss: 0.012 - ETA: 448s - loss: 0.012 - ETA: 439s - loss: 0.012 - ETA: 430s - loss: 0.012 - ETA: 421s - loss: 0.012 - ETA: 412s - loss: 0.012 - ETA: 403s - loss: 0.012 - ETA: 393s - loss: 0.012 - ETA: 384s - loss: 0.012 - ETA: 375s - loss: 0.012 - ETA: 366s - loss: 0.012 - ETA: 357s - loss: 0.012 - ETA: 347s - loss: 0.012 - ETA: 338s - loss: 0.012 - ETA: 329s - loss: 0.012 - ETA: 320s - loss: 0.012 - ETA: 311s - loss: 0.012 - ETA: 302s - loss: 0.012 - ETA: 292s - loss: 0.012 - ETA: 283s - loss: 0.012 - ETA: 274s - loss: 0.012 - ETA: 265s - loss: 0.012 - ETA: 256s - loss: 0.012 - ETA: 246s - loss: 0.012 - ETA: 237s - loss: 0.012 - ETA: 228s - loss: 0.012 - ETA: 219s - loss: 0.012 - ETA: 210s - loss: 0.012 - ETA: 201s - loss: 0.012 - ETA: 191s - loss: 0.012 - ETA: 182s - loss: 0.012 - ETA: 173s - loss: 0.012 - ETA: 164s - loss: 0.012 - ETA: 155s - loss: 0.012 - ETA: 145s - loss: 0.012 - ETA: 136s - loss: 0.012 - ETA: 127s - loss: 0.012 - ETA: 118s - loss: 0.012 - ETA: 109s - loss: 0.012 - ETA: 99s - loss: 0.012 - ETA: 90s - loss: 0.01 - ETA: 81s - loss: 0.01 - ETA: 72s - loss: 0.01 - ETA: 63s - loss: 0.01 - ETA: 54s - loss: 0.01 - ETA: 44s - loss: 0.01 - ETA: 35s - loss: 0.01 - ETA: 26s - loss: 0.01 - ETA: 17s - loss: 0.01 - ETA: 8s - loss: 0.0121 - 1964s - loss: 0.0121 - val_loss: 0.0131\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation, Cropping2D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "\n",
    "lines=[]\n",
    "with open(\"./driving_data_example/driving_log.csv\") as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "\n",
    "images=[]\n",
    "movements=[]\n",
    "for line in lines:\n",
    "    source_path_center= line[0]\n",
    "    source_path_left= line[1]\n",
    "    source_path_right= line[2]\n",
    "\n",
    "    filename_center= source_path_center.split('/')[-1]\n",
    "    # filename_left= source_path_left.split('/')[-1]\n",
    "    # filename_right= source_path_right.split('/')[-1]\n",
    "\n",
    "    current_path_center= './driving_data_example/IMG/' + filename_center\n",
    "    # current_path_left= './driving_data_example/IMG/' + filename_left\n",
    "    # current_path_right= './driving_data_example/IMG/' + filename_right\n",
    "\n",
    "    image_center=cv2.imread(current_path_center)\n",
    "    # image_left=cv2.imread(current_path_left)\n",
    "    # image_right=cv2.imread(current_path_right)\n",
    "    \n",
    "    movement_center=float(line[3])\n",
    "    # correction= 0.2\n",
    "    # movement_left= movement_center+correction\n",
    "    # movement_right= movement_center-correction\n",
    "    \n",
    "    # images.extend([image_center, image_left, image_right])\n",
    "    # movements.extend([movement_center, movement_left, movement_right])\n",
    "    images.append(image_center)\n",
    "    movements.append(movement_center)\n",
    "    \n",
    "\n",
    "# fliped the images, movements into augmented_images and augmented_movements\n",
    "# augmented_images, augmented_movements= [], []\n",
    "# for image, movement in tqdm(zip(images, movements)):\n",
    "    # augmented_images.append(image)\n",
    "    # augmented_movements.append(movement)\n",
    "    # augmented_images.append(np.fliplr(image))\n",
    "    # augmented_movements.append(-movement)\n",
    "    \n",
    "# turn the type of \"augmented_images\", \"augmented_movements\"  from list into array,\n",
    "# cause the keras only accept array type dataset.\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(movements)\n",
    "\n",
    "# train the model\n",
    "model=Sequential()\n",
    "# preprocessing\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0)), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: x/255 - 0.5))\n",
    "\n",
    "# using the NVIDIA self_driving network, it include 5 CNNs and 4 fully connected layers\n",
    "# CNN layer 1\n",
    "model.add(Conv2D(24, 5, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# CNN layer 2\n",
    "model.add(Conv2D(36, 5, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# CNN layer 3\n",
    "model.add(Conv2D(48, 5, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# CNN layer 4\n",
    "model.add(Conv2D(64, 3, 1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# CNN layer 5\n",
    "model.add(Conv2D(64, 3, 1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(X_train))\n",
    "# model.add(Convolution2D(6, 5, 5, input_shape=(160, 320, 3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Convolution2D(6, 5, 6)\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Convolution2D(6, 5, 6)\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
